#Import module

import os
import sys
import shutil
import random
import cv2
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from keras.applications.vgg16 import VGG16
import numpy as np
import matplotlib.pyplot as plt


#Trim photo to same size.

def crop_photo(photo_path, save_path):
    path = photo_path
    img = cv2.imread(path)
    cropped_img = img[1000:2000, 500:1500]
    cv2.imwrite(save_path, cropped_img)


"""
Create photos from a movie
dir_path is directory to save photos
basename is the name of photos saved in dir_path
"""

def save_all_frames(video_path, dir_path, basename, ext = "jpg"):
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        return

    os.makedirs(dir_path, exist_ok=True)
    base_path = os.path.join(dir_path, basename)

    digit = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))

    n = 0

    while True:
        ret, frame = cap.read()
        if ret:
            cv2.imwrite('{}_{}.{}'.format(base_path, str(n).zfill(digit), ext), frame)
            n += 1
        else:
            return


#Split train and val data

def image_dir_train_val_split(original_dir, base_dir, train_size = 0.8):
    try:
        os.mkdir(base_dir)
    except FileExistsError:
        print(base_dir + 'is already created.')

    #Get class name from directory name
  
    dir_lists = os.listdir(original_dir)
    dir_llists = [f for f in dir_lists if os.path.isdir(os.path.join(original_dir, f))]
    original_dir_path = [os.path.join(original_dir, p) for p in dir_lists]

    try:
        train_dir = os.path.join(base_dir, 'train')
        os.mkdir(train_dir)
    except FileExistsError:
        print(train_dir + 'is already creatd.')

    try:
        validation_dir = os.path.join(base_dir, 'val')
        os.mkdir(validation_dir)
    except FileExistsError:
        print(validation_dir + 'is already created.')

    train_dir_path_lists = []
    val_dir_path_lists = []
    for D in dir_lists:
        train_class_dir_path = os.path.join(train_dir, D)
        try:
            os.mkdir(train_class_dir_path)
        except FileExistsError:
            print(train_class_dir_path + ' is already created.')
        train_dir_path_lists += [train_class_dir_path]
      
        val_class_dir_path = os.path.join(validation_dir, D)
        try:
            os.mkdir(val_class_dir_path)
        except FileExistsError:
            print(val_class_dir_path + ' is already created.')
        val_dir_path_lists += [val_class_dir_path]

    for i, path in enumerate(original_dir_path):
        files_class = os.listdir(path)
        random.shuffle(files_class)
        num_bunkaku = int(len(files_class) * train_size)
        for fname in files_class[:num_bunkaku]:
            src = os.path.join(path, fname)
            dst = os.path.join(train_dir_path_lists[i], fname)
            shutil.copyfile(src, dst)
        for fname in files_class[num_bunkaku:]:
            src = os.path.join(path, fname)
            dst = os.path.join(val_dir_path_lists[i], fname)
            shutil.copyfile(src, dst)

    print("processing is done")


"""
Image augmentation by using image data generator
train and validation photos are saved each train and validation folder.
train data and val data are generated by image data generator.
"""

def ImageDataGenerate(train_dir, validation_dir):

    batch_size = 32
    IMG_HEIGHT = 224
    IMG_WIDTH = 224

    train_image_generator = ImageDataGenerator(
        rescale = 1 / 255,
        rotation_range = 30,
        #shear_range = 0.2,
        horizontal_flip = True,
        fill_mode = 'nearest',
        width_shift_range = 0.1,
        height_shift_range = 0.1,
        brightness_range = [0.3, 0.8]
        )

    validation_image_generator = ImageDataGenerator(
        rescale = 1 / 255,
        rotation_range = 30,
        #shear_range = 0.2,
        horizontal_flip = True,
        fill_mode = 'nearest',
        width_shift_range = 0.1,
        height_shift_range = 0.1,
        brightness_range = [0.3, 0.8])

    train_data_gen = train_image_generator.flow_from_directory(
        batch_size = batch_size,
        directory = train_dir,
        shuffle = True,
        target_size = (IMG_HEIGHT, IMG_WIDTH),
        class_mode = "binary")

    val_data_gen = validation_image_generator.flow_from_directory(
        batch_size = batch_size,
        directory = validation_dir,
        shuffle = True,
        target_size = (IMG_HEIGHT, IMG_WIDTH),
        class_mode = 'binary')

    return train_data_gen, val_data_gen


#VGG

def VGG_model():
    model_vgg16 = VGG16(include_top = False, weights = "imagenet", input_tensor = Input(shape = (224, 224, 3)))
    x = model_vgg16.output
    x = Flatten()(x)
    x = Dense(256)(x)
    x = Activation("relu")(x)
    x = Dropout(0.5)(x)
    prediction = Dense(1, activation = "sigmoid")(x)
    model = Model(inputs = model_vgg16.input, outputs = prediction)
    return model_vgg16, model


"""
Data augumentation. Photos are saved in train and valid folders.
"""

def DataAugumentation(train_photos, val_photos):
    train_data_gen, val_data_gen = ImageDataGenerate(train_photos, val_photos)
    return train_data_gen, val_data_gen


#Training VGG model

def training(model_vgg16, model):
    for layer in model_vgg16.layers[:19]:
         layer.trainable = False

    model.compile(loss = "binary_crossentropy",
                  optimizer = Adam(learning_rate = 0.001),
                  metrics = ['accuracy'])

    history = model.fit(train_data_gen,
                        epochs = 50,
                        verbose = 1,
                        validation_data = val_data_gen,
                        callbacks = [EarlyStopping(patience = 5)])

    return model, history

#Save model

def save_model(model, h5_filename):
  model.save(h5filename)

#Plot accuracy and loss

def plot_acc_loss(history):
    plt.plot(history.history['accuracy'], "-", label = "accuracy")
    plt.plot(history.history['val_accuracy'], "-", label = "val_acc")
    plt.title("accuracy")
    plt.xlabel("epoch")
    plt.ylabel("accuracy")
    plt.legend(loc = "lower right")
    plt.show()

    plt.plot(history.history['loss'], "-", label = "loss")
    plt.plot(history.history['val_loss'], '-', label = 'val_loss')
    plt.title('loss')
    plt.xlabel("epoch")
    plt.ylabel("loss")
    plt.legend(loc = "upper right")
    plt.show()
